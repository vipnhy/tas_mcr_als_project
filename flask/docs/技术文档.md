# TAS MCR-ALS 分析平台 - 技术文档

## 📋 目录
- [技术架构](#技术架构)
- [部署指南](#部署指南)
- [API文档](#api文档)
- [数据格式规范](#数据格式规范)
- [算法原理](#算法原理)
- [性能优化](#性能优化)
- [故障排除](#故障排除)

---

## 🏗️ 技术架构

### 整体架构图

```
┌─────────────────────────────────────────────────────────────┐
│                     用户浏览器                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │ HTML/CSS/JS │  │  Bootstrap  │  │ Font Awesome│          │
│  └─────────────┘  └─────────────┘  └─────────────┘          │
└─────────────────┬───────────────────────────────────────────┘
                  │ HTTP/AJAX
┌─────────────────┴───────────────────────────────────────────┐
│                   Flask Web服务器                           │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │   路由处理   │  │   会话管理   │  │   文件处理   │          │
│  └─────────────┘  └─────────────┘  └─────────────┘          │
├─────────────────────────────────────────────────────────────┤
│                   MCR-ALS算法层                             │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │  数据预处理  │  │  算法计算    │  │  结果生成    │          │
│  └─────────────┘  └─────────────┘  └─────────────┘          │
├─────────────────────────────────────────────────────────────┤
│                   数据存储层                                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │  上传文件    │  │  临时数据    │  │  结果文件    │          │
│  └─────────────┘  └─────────────┘  └─────────────┘          │
└─────────────────────────────────────────────────────────────┘
```

### 目录结构

```
flask/
├── app.py                    # Flask主应用
├── run_server.py            # 服务器启动脚本
├── core_analyzer.py         # MCR-ALS核心分析模块
├── requirements.txt         # Python依赖包
├── static/                  # 静态资源
│   ├── css/
│   │   └── style.css       # 自定义样式
│   ├── js/
│   │   └── app.js          # 前端交互逻辑
│   └── images/             # 图片资源
├── templates/              # Jinja2模板
│   ├── base.html          # 基础模板
│   ├── index.html         # 主页
│   ├── upload.html        # 上传页面
│   ├── analyze.html       # 分析页面
│   ├── results.html       # 结果页面
│   ├── sessions.html      # 历史会话
│   └── 404.html           # 错误页面
├── uploads/               # 上传文件存储
├── results/              # 分析结果存储
└── docs/                 # 文档目录
    ├── 使用指南.md
    └── 技术文档.md
```

---

## 🚀 部署指南

### 环境要求

- **Python**: 3.8或更高版本
- **内存**: 最小2GB，推荐4GB
- **存储**: 最小500MB可用空间
- **网络**: HTTP端口5000访问权限

### 快速部署

#### 1. 克隆项目
```bash
git clone https://github.com/your-repo/tas_mcr_als_project.git
cd tas_mcr_als_project/flask
```

#### 2. 创建虚拟环境
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/macOS
python3 -m venv venv
source venv/bin/activate
```

#### 3. 安装依赖
```bash
pip install -r requirements.txt
```

#### 4. 启动服务
```bash
python run_server.py
```

#### 5. 访问应用
打开浏览器访问：`http://localhost:5000`

### 生产环境部署

#### 使用Gunicorn (Linux)
```bash
# 安装Gunicorn
pip install gunicorn

# 启动服务
gunicorn -w 4 -b 0.0.0.0:5000 app:app
```

#### 使用Nginx反向代理
```nginx
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://127.0.0.1:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    location /static {
        alias /path/to/flask/static;
        expires 30d;
    }
}
```

#### Docker部署
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 5000

CMD ["python", "run_server.py"]
```

---

## 📡 API文档

### 路由端点

#### 1. 主页
```
GET /
描述: 返回主页HTML
响应: index.html模板
```

#### 2. 文件上传页面
```
GET /upload
描述: 返回上传页面HTML
响应: upload.html模板
```

#### 3. 文件上传处理
```
POST /upload
描述: 处理文件上传和分析参数
参数:
  - file: 上传的数据文件
  - components: 组分数量 (int)
  - max_iterations: 最大迭代次数 (int)
  - wavelength_min: 最小波长 (float)
  - wavelength_max: 最大波长 (float)
  - delay_min: 最小延迟 (float)
  - delay_max: 最大延迟 (float)
  - language: 界面语言 (str)
响应: 重定向到分析页面
```

#### 4. 分析页面
```
GET /analyze/<session_id>
描述: 返回分析进度页面
参数: session_id - 会话ID
响应: analyze.html模板
```

#### 5. 开始分析
```
POST /start_analysis/<session_id>
描述: 启动MCR-ALS分析
参数: session_id - 会话ID
响应: JSON状态信息
```

#### 6. 分析状态
```
GET /analysis_status/<session_id>
描述: 获取实时分析状态
参数: session_id - 会话ID
响应: JSON格式的状态和日志
```

#### 7. 结果页面
```
GET /results/<session_id>
描述: 返回分析结果页面
参数: session_id - 会话ID
响应: results.html模板
```

#### 8. 图表预览
```
GET /preview_chart/<session_id>/<chart_type>
描述: 预览分析图表
参数:
  - session_id: 会话ID
  - chart_type: 图表类型 (concentration/spectra/lof)
响应: PNG图片
```

#### 9. 文件下载
```
GET /download/<session_id>/<filename>
描述: 下载结果文件
参数:
  - session_id: 会话ID
  - filename: 文件名
响应: 文件下载
```

#### 10. 批量下载
```
GET /download_all/<session_id>
描述: 下载所有结果文件
参数: session_id - 会话ID
响应: ZIP压缩包下载
```

### 响应格式

#### 成功响应
```json
{
    "status": "success",
    "message": "操作成功",
    "data": {
        // 具体数据
    }
}
```

#### 错误响应
```json
{
    "status": "error",
    "message": "错误描述",
    "error_code": "ERROR_CODE"
}
```

#### 分析状态响应
```json
{
    "status": "running|completed|error",
    "progress": 75,
    "current_step": "MCR计算中",
    "iteration": 45,
    "max_iteration": 100,
    "lof": 92.5,
    "logs": [
        {"level": "info", "message": "开始分析...", "timestamp": "..."},
        {"level": "success", "message": "收敛成功", "timestamp": "..."}
    ]
}
```

---

## 📊 数据格式规范

### 输入数据格式

#### CSV格式示例
```csv
Wavelength(nm),0.1ps,0.2ps,0.5ps,1ps,2ps,5ps,10ps,20ps,50ps,100ps
350,0.001,0.002,0.003,0.004,0.005,0.004,0.003,0.002,0.001,0.000
351,0.002,0.003,0.004,0.005,0.006,0.005,0.004,0.003,0.002,0.001
352,0.003,0.004,0.005,0.006,0.007,0.006,0.005,0.004,0.003,0.002
...
700,0.000,0.001,0.002,0.001,0.000,-0.001,-0.002,-0.001,0.000,0.001
```

#### 数据要求
- **第一行**: 标题行，包含波长标签和时间延迟值
- **第一列**: 波长值，单位为纳米(nm)
- **数据列**: 对应时间延迟的吸光度值
- **数值格式**: 浮点数，支持科学计数法
- **分隔符**: 逗号或制表符
- **编码**: UTF-8

### 输出数据格式

#### 1. 浓度轮廓数据 (concentration_data.csv)
```csv
Time(ps),Component_1,Component_2,Component_3
0.1,0.847,0.123,0.030
0.2,0.821,0.151,0.028
0.5,0.754,0.208,0.038
1.0,0.651,0.284,0.065
2.0,0.523,0.371,0.106
5.0,0.342,0.457,0.201
10.0,0.198,0.502,0.300
20.0,0.087,0.485,0.428
50.0,0.021,0.379,0.600
100.0,0.003,0.257,0.740
```

#### 2. 纯光谱数据 (spectra_data.csv)
```csv
Wavelength(nm),Component_1,Component_2,Component_3
350,0.012,-0.003,0.001
351,0.015,-0.004,0.002
352,0.018,-0.005,0.003
...
700,-0.002,0.001,-0.001
```

#### 3. 收敛历史 (lof_history.csv)
```csv
Iteration,LOF_Percent,Convergence_Criteria
1,98.52,0.0
2,96.18,2.34
3,94.83,1.35
4,93.71,1.12
...
78,90.13,0.08
```

#### 4. 分析参数 (analysis_parameters.json)
```json
{
    "input_file": "example_data.csv",
    "components": 3,
    "max_iterations": 100,
    "convergence_criteria": 0.1,
    "wavelength_range": [350, 700],
    "delay_range": [0.1, 100],
    "language": "中文",
    "analysis_time": "2025-08-28 14:30:25",
    "final_lof": 90.13,
    "iterations_used": 78,
    "convergence_achieved": true
}
```

---

## 🔬 算法原理

### MCR-ALS算法概述

多元曲线分辨-交替最小二乘法(MCR-ALS)是一种用于分离重叠信号的化学计量学方法，特别适用于瞬态吸收光谱数据分析。

#### 数学模型

原始数据矩阵可以表示为：
```
D = C × S^T + E
```

其中：
- `D`: 实验数据矩阵 (m×n)
- `C`: 浓度轮廓矩阵 (m×r)
- `S^T`: 纯光谱矩阵的转置 (r×n)
- `E`: 残差矩阵 (m×n)
- `m`: 时间点数
- `n`: 波长点数
- `r`: 化学组分数

#### 算法流程

```
1. 初始化:
   ┌─────────────────────────────────────────┐
   │ a) 使用SIMPLISMA算法估计初始纯光谱     │
   │ b) 计算对应的初始浓度轮廓               │
   └─────────────────────────────────────────┘
                        ↓
2. 交替最小二乘迭代:
   ┌─────────────────────────────────────────┐
   │ while (not converged):                  │
   │   a) 固定S，求解C: C = D × S × (S^T×S)^-1│
   │   b) 应用浓度约束 (非负性等)            │
   │   c) 固定C，求解S^T: S^T = (C^T×C)^-1×C^T×D│
   │   d) 应用光谱约束 (归一化等)            │
   │   e) 计算LOF，检查收敛性                │
   └─────────────────────────────────────────┘
                        ↓
3. 结果输出:
   ┌─────────────────────────────────────────┐
   │ a) 最终浓度轮廓矩阵C                    │
   │ b) 最终纯光谱矩阵S                      │
   │ c) 拟合质量指标LOF                      │
   └─────────────────────────────────────────┘
```

#### 收敛判据

缺失拟合度(Lack of Fit, LOF)定义为：
```
LOF = 100 × √(Σ(D_ij - D_fit_ij)²) / √(Σ(D_ij)²)
```

当连续迭代的LOF变化小于设定阈值(通常0.1%)时，认为算法收敛。

#### 约束条件

1. **非负性约束**: 浓度和光谱值不能为负
2. **归一化约束**: 浓度轮廓归一化为0-1范围
3. **质量平衡**: 确保总浓度守恒

### SIMPLISMA初始化

简单交替最小自建模(SIMPLISMA)算法用于估计初始纯光谱：

```python
def simplisma_initialization(data, n_components):
    """
    SIMPLISMA算法实现
    """
    purity = calculate_purity(data)
    pure_indices = []
    
    for i in range(n_components):
        max_purity_idx = find_max_purity(purity)
        pure_indices.append(max_purity_idx)
        update_purity(purity, data[:, max_purity_idx])
    
    return data[:, pure_indices]
```

---

## ⚡ 性能优化

### 前端优化

#### 1. 资源压缩
- CSS/JS文件压缩
- 图片格式优化
- 字体文件压缩

#### 2. 缓存策略
```javascript
// 设置静态资源缓存
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 31536000  // 1年

// 版本控制
<link rel="stylesheet" href="style.css?v=1.0.0">
```

#### 3. 异步加载
```javascript
// 使用Promise进行异步操作
async function checkAnalysisStatus(sessionId) {
    try {
        const response = await fetch(`/analysis_status/${sessionId}`);
        const data = await response.json();
        updateProgressDisplay(data);
    } catch (error) {
        console.error('Status check failed:', error);
    }
}
```

### 后端优化

#### 1. 数据结构优化
```python
# 使用NumPy向量化操作
import numpy as np

# 避免循环，使用矩阵运算
def matrix_multiplication_optimized(A, B):
    return np.dot(A, B)  # 比嵌套循环快10-100倍
```

#### 2. 内存管理
```python
# 及时释放大型数组
del large_array
gc.collect()

# 使用内存映射处理大文件
data = np.memmap('large_file.dat', dtype='float32', mode='r')
```

#### 3. 并行计算
```python
from concurrent.futures import ThreadPoolExecutor

def parallel_analysis(data_chunks):
    with ThreadPoolExecutor(max_workers=4) as executor:
        results = list(executor.map(analyze_chunk, data_chunks))
    return combine_results(results)
```

### 算法优化

#### 1. 收敛加速
```python
def adaptive_convergence_check(lof_history, tolerance=0.1):
    """
    自适应收敛检测
    """
    if len(lof_history) < 5:
        return False
    
    recent_change = np.mean(np.diff(lof_history[-5:]))
    return abs(recent_change) < tolerance
```

#### 2. 稀疏矩阵优化
```python
from scipy.sparse import csr_matrix

# 对于稀疏数据使用稀疏矩阵
if sparsity_ratio(data) > 0.8:
    sparse_data = csr_matrix(data)
    # 使用稀疏矩阵算法
```

---

## 🔧 故障排除

### 常见错误及解决方案

#### 1. 模块导入错误
```
错误: ModuleNotFoundError: No module named 'flask'
解决: 确保已激活虚拟环境并安装了requirements.txt中的所有依赖
命令: pip install -r requirements.txt
```

#### 2. 端口占用错误
```
错误: OSError: [Errno 48] Address already in use
解决: 更改端口或杀死占用进程
命令: 
# 查找占用进程
lsof -i :5000
# 杀死进程
kill -9 <PID>
```

#### 3. 文件权限错误
```
错误: PermissionError: [Errno 13] Permission denied
解决: 检查文件和目录权限
命令: chmod 755 uploads/ results/
```

#### 4. 内存不足错误
```
错误: MemoryError: Unable to allocate array
解决: 
1. 减少数据大小
2. 增加系统内存
3. 使用数据分块处理
```

#### 5. 收敛失败
```
问题: 算法不收敛或收敛到局部最优
解决:
1. 调整初始值设置
2. 修改收敛判据
3. 增加最大迭代次数
4. 检查数据质量
```

### 调试工具

#### 1. 日志系统
```python
import logging

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)

# 使用日志
logger = logging.getLogger(__name__)
logger.info("分析开始")
logger.error("计算错误: %s", error_message)
```

#### 2. 性能分析
```python
import cProfile
import pstats

# 分析函数性能
def profile_function(func, *args, **kwargs):
    profiler = cProfile.Profile()
    profiler.enable()
    result = func(*args, **kwargs)
    profiler.disable()
    
    stats = pstats.Stats(profiler)
    stats.sort_stats('tottime')
    stats.print_stats()
    
    return result
```

#### 3. 内存监控
```python
import tracemalloc
import psutil

def monitor_memory():
    # 跟踪内存分配
    tracemalloc.start()
    
    # 获取系统内存信息
    memory = psutil.virtual_memory()
    print(f"可用内存: {memory.available / 1024**3:.2f} GB")
    
    # 显示内存使用最多的代码行
    current, peak = tracemalloc.get_traced_memory()
    print(f"当前内存使用: {current / 1024**2:.2f} MB")
    print(f"峰值内存使用: {peak / 1024**2:.2f} MB")
```

### 备份和恢复

#### 1. 数据备份
```bash
#!/bin/bash
# backup.sh - 自动备份脚本

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/tas_mcr_${DATE}"

mkdir -p $BACKUP_DIR
cp -r uploads/ $BACKUP_DIR/
cp -r results/ $BACKUP_DIR/
cp requirements.txt $BACKUP_DIR/
cp app.py $BACKUP_DIR/

echo "备份完成: $BACKUP_DIR"
```

#### 2. 配置管理
```python
# config.py - 配置文件
import os

class Config:
    SECRET_KEY = os.environ.get('SECRET_KEY') or 'dev-secret-key'
    UPLOAD_FOLDER = os.environ.get('UPLOAD_FOLDER') or 'uploads'
    RESULTS_FOLDER = os.environ.get('RESULTS_FOLDER') or 'results'
    MAX_CONTENT_LENGTH = 50 * 1024 * 1024  # 50MB
    
class DevelopmentConfig(Config):
    DEBUG = True
    
class ProductionConfig(Config):
    DEBUG = False
```

---

## 📈 监控和维护

### 系统监控

#### 1. 健康检查端点
```python
@app.route('/health')
def health_check():
    """系统健康检查"""
    try:
        # 检查关键组件
        disk_usage = psutil.disk_usage('/')
        memory_usage = psutil.virtual_memory()
        
        status = {
            'status': 'healthy',
            'disk_free': disk_usage.free,
            'memory_available': memory_usage.available,
            'timestamp': datetime.now().isoformat()
        }
        
        return jsonify(status), 200
    except Exception as e:
        return jsonify({'status': 'unhealthy', 'error': str(e)}), 500
```

#### 2. 指标收集
```python
from prometheus_client import Counter, Histogram, generate_latest

# 定义指标
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests')
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')

@app.route('/metrics')
def metrics():
    """Prometheus指标端点"""
    return generate_latest()
```

### 定期维护

#### 1. 清理脚本
```python
# cleanup.py - 定期清理临时文件
import os
import time
from datetime import datetime, timedelta

def cleanup_old_files(directory, days=7):
    """删除指定天数前的文件"""
    cutoff_time = time.time() - (days * 24 * 60 * 60)
    
    for root, dirs, files in os.walk(directory):
        for file in files:
            file_path = os.path.join(root, file)
            if os.path.getmtime(file_path) < cutoff_time:
                os.remove(file_path)
                print(f"已删除: {file_path}")

if __name__ == "__main__":
    cleanup_old_files('uploads', days=7)
    cleanup_old_files('results', days=30)
```

#### 2. 数据库维护(如有)
```python
# 如果使用数据库，定期维护示例
def database_maintenance():
    """数据库维护任务"""
    # 清理过期会话
    expired_sessions = Session.query.filter(
        Session.created_at < datetime.now() - timedelta(days=30)
    ).all()
    
    for session in expired_sessions:
        db.session.delete(session)
    
    db.session.commit()
    print(f"清理了 {len(expired_sessions)} 个过期会话")
```

---

*技术文档版本：v1.0.0*  
*最后更新：2025年8月28日*  
*维护团队：TAS-MCR-ALS开发团队*
