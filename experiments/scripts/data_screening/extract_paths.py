#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
TASç­›é€‰æ•°æ®è·¯å¾„æå–å™¨
ä¸“é—¨æå–å’Œæ˜¾ç¤ºç­›é€‰å‡ºçš„æŒ‘æˆ˜æ€§æ•°æ®çš„è·¯å¾„ä¿¡æ¯
"""

import json
from pathlib import Path

RESULTS_DIR = Path("experiments/results/data_screening")

def extract_screened_data_paths():
    """æå–ç­›é€‰å‡ºçš„æ•°æ®è·¯å¾„"""
    results_file = RESULTS_DIR / "screening_results.json"

    if not results_file.exists():
        print("âŒ æ‰¾ä¸åˆ°ç­›é€‰ç»“æœæ–‡ä»¶")
        return

    with open(results_file, 'r', encoding='utf-8') as f:
        results = json.load(f)

    print("ğŸ¯ TASæŒ‘æˆ˜æ€§æ•°æ®ç­›é€‰ç»“æœ - è·¯å¾„ä¿¡æ¯")
    print("=" * 60)

    total_files = 0

    for category, title in [
        ('multi_peak_overlap', 'å¤šå³°é‡å æ•°æ®'),
        ('transient_decay', 'ç¬æ€è¡°å‡æ•°æ®'),
        ('low_snr', 'ä½ä¿¡å™ªæ¯”æ•°æ®')
    ]:
        files = results.get(category, [])
        if files:
            print(f"\nğŸ¯ {title} ({len(files)} ä¸ªæ–‡ä»¶):")
            print("-" * 40)

            for i, file_info in enumerate(files, 1):
                print(f"{i}. {file_info['file_name']}")
                print(f"   ğŸ“‚ ç»å¯¹è·¯å¾„: {file_info['file_path']}")
                print(f"   ğŸ“ ç›¸å¯¹è·¯å¾„: {file_info.get('relative_path', file_info['file_path'])}")
                print(f"   ğŸ“Š æ•°æ®å½¢çŠ¶: {file_info['shape'][0]}Ã—{file_info['shape'][1]}")
                print(f"   ğŸ“ˆ æ³¢é•¿èŒƒå›´: {file_info['wavelength_range'][0]:.1f} - {file_info['wavelength_range'][1]:.1f} nm")
                print(f"   â±ï¸  æ—¶é—´èŒƒå›´: {file_info['time_range'][0]:.2f} - {file_info['time_range'][1]:.2f} ps")
                print()

            total_files += len(files)

    print("=" * 60)
    print(f"ğŸ“Š æ€»è®¡ç­›é€‰å‡º {total_files} ä¸ªæŒ‘æˆ˜æ€§æ•°æ®æ–‡ä»¶")
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("- ç»å¯¹è·¯å¾„å¯ç”¨äºè„šæœ¬ç›´æ¥è®¿é—®æ–‡ä»¶")
    print("- ç›¸å¯¹è·¯å¾„æ˜¾ç¤ºæ–‡ä»¶åœ¨é¡¹ç›®ä¸­çš„ä½ç½®")
    print("- å¯è§†åŒ–æ–‡ä»¶ä¿å­˜åœ¨å¯¹åº”ç±»åˆ«ç›®å½•ä¸­")

    # ç”Ÿæˆè·¯å¾„åˆ—è¡¨æ–‡ä»¶
    paths_file = RESULTS_DIR / "screened_data_paths.txt"
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)

    with open(paths_file, 'w', encoding='utf-8') as f:
        f.write("# TASæŒ‘æˆ˜æ€§æ•°æ®ç­›é€‰ç»“æœ - æ–‡ä»¶è·¯å¾„åˆ—è¡¨\n")
        f.write(f"# ç”Ÿæˆæ—¶é—´: {Path('.').resolve()}\n\n")

        for category, title in [('multi_peak_overlap', 'å¤šå³°é‡å æ•°æ®'),
                               ('transient_decay', 'ç¬æ€è¡°å‡æ•°æ®'),
                               ('low_snr', 'ä½ä¿¡å™ªæ¯”æ•°æ®')]:
            files = results.get(category, [])
            if files:
                f.write(f"## {title}\n")
                for file_info in files:
                    f.write(f"# {file_info['file_name']}\n")
                    f.write(f"{file_info['file_path']}\n")
                    f.write(f"{file_info.get('relative_path', file_info['file_path'])}\n\n")

    print(f"\nğŸ“„ è·¯å¾„åˆ—è¡¨å·²ä¿å­˜: {paths_file}")

if __name__ == "__main__":
    extract_screened_data_paths()